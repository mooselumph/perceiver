{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e61c15d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ['XLA_FLAGS']='--xla_gpu_deterministic_reductions'\n",
    "# os.environ['TF_CUDNN_DETERMINISTIC']='1'\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import logging\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d193ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import ConfigSchema\n",
    "config = ConfigSchema(\n",
    "    learning_rate = 0.001,\n",
    "    momentum = 0.9,\n",
    "    batch_size = 30,\n",
    "    num_epochs = 10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "213ee0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "%aimport train_stead\n",
    "%aimport model.model\n",
    "%aimport data\n",
    "\n",
    "models = model.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28f730d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_tie_pattern = tuple([0,*np.ones(7,dtype=int)])\n",
    "\n",
    "perceiver = models.Perceiver(\n",
    "    \n",
    "    input_shape = (600,3),\n",
    "    \n",
    "    weight_tie_pattern = weight_tie_pattern,\n",
    "                                 # depth of net. The shape of the final attention mechanism will be:\n",
    "                                 #   depth * (cross attention -> self_per_cross_attn * self attention)\n",
    "    \n",
    "    num_freq_bands = 6,          # number of freq bands, with original value (2 * K + 1)\n",
    "    max_freq = 20.,              # maximum frequency, hyperparameter depending on how fine the data is\n",
    "    freq_base = 2,               \n",
    "\n",
    "    num_latents = 64,            # number of latents, or induced set points, or centroids. different papers giving it different names\n",
    "    latent_dim = 32,             # latent dimension\n",
    "    \n",
    "    cross_heads = 1,             # number of heads for cross attention. paper said 1\n",
    "    cross_head_dim = 64,         # number of dimensions per cross attention head\n",
    "    \n",
    "    latent_heads = 8,            # number of heads for latent self attention, 8\n",
    "    latent_head_dim = 16,        # number of dimensions per latent self attention head\n",
    "    \n",
    "    num_classes = 2,            # output number of classes\n",
    "    attn_dropout = 0.,\n",
    "    ff_dropout = 0.,\n",
    "    fourier_encode_data = True,  # whether to auto-fourier encode the data, using the input_axis given. defaults to True, but can be turned off if you are fourier encoding the data yourself\n",
    "    self_per_cross_attn = 2      # number of self attention blocks per cross attention\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "9ab41997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key = jax.random.PRNGKey(0)\n",
    "key, subkey = jax.random.split(key)\n",
    "\n",
    "trace = random.normal(subkey,(1, 6000, 3)) # 1 imagenet image, pixelized\n",
    "\n",
    "out, params = perceiver.init_with_output(random.PRNGKey(0),trace)\n",
    "\n",
    "out.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "eeba7f5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 2)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output, mod_vars = perceiver.apply(params, batch_x, mutable='intermediates')\n",
    "jax.nn.softmax(output).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7aef9519",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work/data.py:85: DtypeWarning: Columns (7,11,13,14,15,18,19,20,21,22,24,25,26,30,31) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  gen = stead_generator(hdf_file,csv_file,test_ratio,noise_ratio)\n"
     ]
    }
   ],
   "source": [
    "train_ds,test_ds = data.get_stead(batch_size=config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1068f113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ecf23e3e7874c4db0dbb330f95c208c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Interrupted by user at epoch 2\n"
     ]
    }
   ],
   "source": [
    "state = train_stead.train_and_evaluate(perceiver, train_ds, test_ds, config, workdir='../tensorboard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "9ec09671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c96bcd0c1ed45d8b838f0efbc6291f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "it = iter(test_ds)\n",
    "\n",
    "epoch_loss = []\n",
    "epoch_accuracy = []\n",
    "for batch_x,batch_y in tqdm(it):\n",
    "    _, loss, accuracy = train_stead.apply_model(perceiver, state, batch_x, batch_y)\n",
    "    epoch_loss.append(loss)\n",
    "    epoch_accuracy.append(accuracy)\n",
    "    \n",
    "val_loss = np.mean(epoch_loss)\n",
    "val_accuracy = np.mean(epoch_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
